{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37664ece",
   "metadata": {},
   "source": [
    "- http://keunwoochoi.blogspot.com/2016/03/2.html\n",
    "- http://www.rex-ai.info/docs/AI_Example_CNN_speech_recognize\n",
    "- https://www.youtube.com/watch?v=oltGIc4uo5c\n",
    "- https://youdaeng-com.tistory.com/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "275b8092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version :  1.10.0  Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # 인공 신경망 모델들 모아놓은 모듈\n",
    "import torch.nn.functional as F #그중 자주 쓰이는것들을 F로\n",
    "from torchvision import transforms, datasets\n",
    "import cv2\n",
    "from torchvision import transforms, datasets\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "p = os.path.abspath('..') # 상위 폴더를 사용하기 위해서.\n",
    "sys.path.insert(1, p)\n",
    "from pytorchtools.pytorchtools import EarlyStopping # 현재 폴더에 추가된 모듈.\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "print('Using Pytorch version : ',torch.__version__,' Device : ',DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ebea6",
   "metadata": {},
   "source": [
    "# SVD 문장 데이터에서 Feature 추출\n",
    "- mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114a1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72d82e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathology data 수 :  1354\n",
      "healthy data 수 :  687\n",
      "가장 긴 path sample : 126051\n",
      "가장 긴 healthy sample : 226236\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "pathology_sig=[]\n",
    "healthy_sig=[]\n",
    "\n",
    "pathology=[]\n",
    "healthy=[]\n",
    "\n",
    "\n",
    "#PATHOLOGY DATA\n",
    "for audio_path in os.listdir('../../voice_data/pathology_i/export/'):\n",
    "    sig, sr = librosa.load('../../voice_data/pathology_i/export/'+audio_path, sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "    pathology_sig.append(sig)\n",
    "    MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    pathology.append(MFCCs)\n",
    "    \n",
    "\n",
    "#Healthy data\n",
    "for audio_path in os.listdir('../../voice_data/healthy_i/export/'):\n",
    "    sig, sr = librosa.load('../../voice_data/healthy_i/export/'+audio_path, sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "    healthy_sig.append(sig)\n",
    "    MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    healthy.append(MFCCs)\n",
    "    \n",
    "print(\"pathology data 수 : \",len(pathology))\n",
    "print(\"healthy data 수 : \",len(healthy))\n",
    "\n",
    "\n",
    "path_max=max([ len(samples) for samples in pathology_sig])\n",
    "healthy_max=max([ len(samples) for samples in healthy_sig])\n",
    "print(\"가장 긴 path sample :\" ,path_max)\n",
    "print(\"가장 긴 healthy sample :\" ,healthy_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636bede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.52102 초\n",
      "4.52472 초\n"
     ]
    }
   ],
   "source": [
    "print(path_max/sr,\"초\")\n",
    "print(healthy_max/sr,\"초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5915f64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 :  1.3254399704579025\n",
      "평균 :  1.4290190684133917\n"
     ]
    }
   ],
   "source": [
    "print('평균 : ',np.mean([ len(samples) for samples in pathology_sig])/sr)\n",
    "print('평균 : ',np.mean([ len(samples) for samples in healthy_sig])/sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91bd1989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.504"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400*313/sr\n",
    "#400 frame은 약 2.5초 이상."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ec668",
   "metadata": {},
   "source": [
    "# 결과 확인\n",
    "- 1 row당 1 frame으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a48f3297",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>mfcc5</th>\n",
       "      <th>mfcc6</th>\n",
       "      <th>mfcc7</th>\n",
       "      <th>mfcc8</th>\n",
       "      <th>mfcc9</th>\n",
       "      <th>mfcc10</th>\n",
       "      <th>mfcc11</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-257.624054</td>\n",
       "      <td>101.441605</td>\n",
       "      <td>11.431145</td>\n",
       "      <td>104.284782</td>\n",
       "      <td>12.844074</td>\n",
       "      <td>30.858997</td>\n",
       "      <td>-23.006546</td>\n",
       "      <td>2.733066</td>\n",
       "      <td>9.088483</td>\n",
       "      <td>7.039111</td>\n",
       "      <td>-10.334429</td>\n",
       "      <td>-11.233789</td>\n",
       "      <td>8.435503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-257.419067</td>\n",
       "      <td>105.031265</td>\n",
       "      <td>5.871933</td>\n",
       "      <td>103.881897</td>\n",
       "      <td>9.893070</td>\n",
       "      <td>31.431822</td>\n",
       "      <td>-28.251961</td>\n",
       "      <td>2.587878</td>\n",
       "      <td>9.513090</td>\n",
       "      <td>6.644758</td>\n",
       "      <td>-10.730095</td>\n",
       "      <td>-7.525294</td>\n",
       "      <td>8.861940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-268.067444</td>\n",
       "      <td>97.532532</td>\n",
       "      <td>-0.844803</td>\n",
       "      <td>97.117706</td>\n",
       "      <td>4.381507</td>\n",
       "      <td>32.494549</td>\n",
       "      <td>-30.492897</td>\n",
       "      <td>8.963182</td>\n",
       "      <td>12.760096</td>\n",
       "      <td>2.586401</td>\n",
       "      <td>-17.708195</td>\n",
       "      <td>-13.206583</td>\n",
       "      <td>5.997622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-265.217255</td>\n",
       "      <td>103.015350</td>\n",
       "      <td>0.299210</td>\n",
       "      <td>96.632637</td>\n",
       "      <td>5.642620</td>\n",
       "      <td>31.900784</td>\n",
       "      <td>-27.334534</td>\n",
       "      <td>13.026344</td>\n",
       "      <td>13.372935</td>\n",
       "      <td>1.548650</td>\n",
       "      <td>-19.601070</td>\n",
       "      <td>-20.358650</td>\n",
       "      <td>6.491438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-273.240997</td>\n",
       "      <td>99.064453</td>\n",
       "      <td>-0.932297</td>\n",
       "      <td>102.358727</td>\n",
       "      <td>9.351763</td>\n",
       "      <td>33.117325</td>\n",
       "      <td>-21.290325</td>\n",
       "      <td>6.766669</td>\n",
       "      <td>11.293850</td>\n",
       "      <td>6.161934</td>\n",
       "      <td>-13.658633</td>\n",
       "      <td>-20.147438</td>\n",
       "      <td>8.825264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>-319.358826</td>\n",
       "      <td>99.801743</td>\n",
       "      <td>11.737771</td>\n",
       "      <td>106.282928</td>\n",
       "      <td>22.124329</td>\n",
       "      <td>35.677372</td>\n",
       "      <td>-23.567856</td>\n",
       "      <td>-9.952773</td>\n",
       "      <td>-5.157382</td>\n",
       "      <td>-4.717806</td>\n",
       "      <td>-5.968917</td>\n",
       "      <td>-0.529867</td>\n",
       "      <td>14.742380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>-319.462280</td>\n",
       "      <td>101.881531</td>\n",
       "      <td>11.020847</td>\n",
       "      <td>107.795593</td>\n",
       "      <td>23.923904</td>\n",
       "      <td>35.095200</td>\n",
       "      <td>-23.819321</td>\n",
       "      <td>-12.773374</td>\n",
       "      <td>-1.936720</td>\n",
       "      <td>-5.520776</td>\n",
       "      <td>-8.793245</td>\n",
       "      <td>-6.701656</td>\n",
       "      <td>9.741186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>-314.436890</td>\n",
       "      <td>101.790909</td>\n",
       "      <td>5.311404</td>\n",
       "      <td>105.077950</td>\n",
       "      <td>24.844336</td>\n",
       "      <td>38.300655</td>\n",
       "      <td>-15.776247</td>\n",
       "      <td>-10.611283</td>\n",
       "      <td>5.813788</td>\n",
       "      <td>-5.038822</td>\n",
       "      <td>-7.109626</td>\n",
       "      <td>-9.563528</td>\n",
       "      <td>6.402265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>-313.523163</td>\n",
       "      <td>99.951782</td>\n",
       "      <td>8.047307</td>\n",
       "      <td>111.989151</td>\n",
       "      <td>17.960836</td>\n",
       "      <td>30.798668</td>\n",
       "      <td>-22.714546</td>\n",
       "      <td>-15.894030</td>\n",
       "      <td>7.621811</td>\n",
       "      <td>0.363993</td>\n",
       "      <td>-1.509025</td>\n",
       "      <td>-10.327892</td>\n",
       "      <td>2.256658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>-305.809143</td>\n",
       "      <td>114.312828</td>\n",
       "      <td>20.389521</td>\n",
       "      <td>119.027878</td>\n",
       "      <td>24.773117</td>\n",
       "      <td>35.625900</td>\n",
       "      <td>-25.438438</td>\n",
       "      <td>-16.555592</td>\n",
       "      <td>-0.157074</td>\n",
       "      <td>-2.125565</td>\n",
       "      <td>-3.486874</td>\n",
       "      <td>-14.503933</td>\n",
       "      <td>-7.731712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mfcc1       mfcc2      mfcc3       mfcc4      mfcc5      mfcc6  \\\n",
       "0   -257.624054  101.441605  11.431145  104.284782  12.844074  30.858997   \n",
       "1   -257.419067  105.031265   5.871933  103.881897   9.893070  31.431822   \n",
       "2   -268.067444   97.532532  -0.844803   97.117706   4.381507  32.494549   \n",
       "3   -265.217255  103.015350   0.299210   96.632637   5.642620  31.900784   \n",
       "4   -273.240997   99.064453  -0.932297  102.358727   9.351763  33.117325   \n",
       "..          ...         ...        ...         ...        ...        ...   \n",
       "326 -319.358826   99.801743  11.737771  106.282928  22.124329  35.677372   \n",
       "327 -319.462280  101.881531  11.020847  107.795593  23.923904  35.095200   \n",
       "328 -314.436890  101.790909   5.311404  105.077950  24.844336  38.300655   \n",
       "329 -313.523163   99.951782   8.047307  111.989151  17.960836  30.798668   \n",
       "330 -305.809143  114.312828  20.389521  119.027878  24.773117  35.625900   \n",
       "\n",
       "         mfcc7      mfcc8      mfcc9    mfcc10     mfcc11     mfcc12  \\\n",
       "0   -23.006546   2.733066   9.088483  7.039111 -10.334429 -11.233789   \n",
       "1   -28.251961   2.587878   9.513090  6.644758 -10.730095  -7.525294   \n",
       "2   -30.492897   8.963182  12.760096  2.586401 -17.708195 -13.206583   \n",
       "3   -27.334534  13.026344  13.372935  1.548650 -19.601070 -20.358650   \n",
       "4   -21.290325   6.766669  11.293850  6.161934 -13.658633 -20.147438   \n",
       "..         ...        ...        ...       ...        ...        ...   \n",
       "326 -23.567856  -9.952773  -5.157382 -4.717806  -5.968917  -0.529867   \n",
       "327 -23.819321 -12.773374  -1.936720 -5.520776  -8.793245  -6.701656   \n",
       "328 -15.776247 -10.611283   5.813788 -5.038822  -7.109626  -9.563528   \n",
       "329 -22.714546 -15.894030   7.621811  0.363993  -1.509025 -10.327892   \n",
       "330 -25.438438 -16.555592  -0.157074 -2.125565  -3.486874 -14.503933   \n",
       "\n",
       "        mfcc13  \n",
       "0     8.435503  \n",
       "1     8.861940  \n",
       "2     5.997622  \n",
       "3     6.491438  \n",
       "4     8.825264  \n",
       "..         ...  \n",
       "326  14.742380  \n",
       "327   9.741186  \n",
       "328   6.402265  \n",
       "329   2.256658  \n",
       "330  -7.731712  \n",
       "\n",
       "[331 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(healthy[0][2]) #1번 : 파일. 2번:mfcc\n",
    "headers = \"mfcc1 mfcc2 mfcc3 mfcc4 mfcc5 mfcc6 mfcc7 mfcc8 mfcc9 mfcc10 mfcc11 mfcc12 mfcc13\".split()\n",
    "pd.DataFrame(healthy[1].T,columns=headers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "186be135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73d328bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pathology\n",
    "del healthy\n",
    "del pathology_sig\n",
    "del healthy_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23a4c15",
   "metadata": {},
   "source": [
    "# 데이터 나누기 - Stratified KFold\n",
    "- k =5\n",
    "- pathology : 1354 / healthy : 687 . 총 : 2041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fada6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathology :  1354\n",
      "Healthy:  687\n",
      "총 데이터수 :  2041\n",
      "교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 549, 'pathology': 1083}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 138, 'pathology': 271} \n",
      "\n",
      "교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 550, 'pathology': 1083}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 137, 'pathology': 271} \n",
      "\n",
      "교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 550, 'pathology': 1083}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 137, 'pathology': 271} \n",
      "\n",
      "교차 검증 : 4\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 550, 'pathology': 1083}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 137, 'pathology': 271} \n",
      "\n",
      "교차 검증 : 5\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 549, 'pathology': 1084}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 138, 'pathology': 270} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "import os\n",
    "import random #데이터 shuffle 사용\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "    \n",
    "pathology = glob('../../voice_data/pathology_i/export/*.wav')\n",
    "healthy = glob('../../voice_data/healthy_i/export/*.wav')\n",
    "print(\"Pathology : \",len(pathology))\n",
    "print(\"Healthy: \",len(healthy))\n",
    "\n",
    "X = pathology+healthy # path 데이터 합\n",
    "print(\"총 데이터수 : \",len(X))\n",
    "Y = [] # 라벨\n",
    "for idx,x in enumerate(X):\n",
    "    if idx<1354:\n",
    "        Y.append(\"pathology\")\n",
    "    else:\n",
    "        Y.append(\"healthy\")\n",
    "\n",
    "\n",
    "skf_iris = StratifiedKFold(n_splits=5)\n",
    "cnt_iter = 0\n",
    "\n",
    "X_train_list = [] #데이터 셋 보관\n",
    "Y_train_list = []\n",
    "\n",
    "X_test_list = []\n",
    "Y_test_list = []\n",
    "\n",
    "for train_idx, test_idx in skf_iris.split(X,Y):\n",
    "    \n",
    "    #split으로 반환된 인덱스를 이용하여, 학습 검증용 테스트 데이터 추출\n",
    "    cnt_iter += 1\n",
    "    X_train, X_test = [X[idx] for idx in train_idx.tolist() ], [X[idx] for idx in test_idx.tolist() ]\n",
    "    Y_train, Y_test = [Y[idx] for idx in train_idx.tolist() ], [Y[idx] for idx in test_idx.tolist() ]\n",
    "    \n",
    "    X_train_list.append(X_train)\n",
    "    X_test_list.append(X_test)\n",
    "    \n",
    "    Y_test_list.append(Y_test)\n",
    "    Y_train_list.append(Y_train)\n",
    "    \n",
    "    #학습 및 예측\n",
    "    \n",
    "    label_train = Y_train\n",
    "    label_test = Y_test\n",
    "    unique_train, train_counts = np.unique(label_train, return_counts = True)\n",
    "    unique_test, test_counts = np.unique(label_test, return_counts = True)\n",
    "    \n",
    "    uniq_cnt_train = dict(zip(unique_train, train_counts))\n",
    "    uniq_cnt_test = dict(zip(unique_test, test_counts))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('교차 검증 : {}'.format(cnt_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', uniq_cnt_train)\n",
    "    print('검증 레이블 데이터 분포 : \\n', uniq_cnt_test,'\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a663f0",
   "metadata": {},
   "source": [
    "# 데이터 정의\n",
    "- 추가적으로 데이터의 크기를 맞춰주기 위해 3초로 padding 및 truncate 실시 https://sequencedata.tistory.com/25 FixAudioLength\n",
    "- 논문에서는 400frame으로 설정.\n",
    "- 전처리 방법 결정.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2febf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "classes = [\"pathology\",\"healthy\"]\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "class svd_dataset(Dataset):\n",
    "    def __init__(self,data_path_list,classes,data_num,training,transform=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list[data_num]\n",
    "        self.data_num = data_num\n",
    "        self.training = training\n",
    "        self.label = svd_dataset.get_label(self.path_list,training,data_num)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list,training,data_num):\n",
    "        label_list=[]\n",
    "        \n",
    "        if training:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_train_list[data_num][idx])\n",
    "        else:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_test_list[data_num][idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다. \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 500프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        sig, sr = librosa.load(self.path_list[idx], sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "        \n",
    "        MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "        #mfcc 400 FRAME이 되도록 패딩.\n",
    "        length = 400\n",
    "        pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
    "        MFCCs = pad2d(MFCCs, length)\n",
    "        MFCCs= MFCCs.T\n",
    "        \n",
    "        if self.transform:\n",
    "            #print('transform')\n",
    "            MFCCs=self.transform(MFCCs).type(torch.float32)# 데이터 0~1 정규화\n",
    "            MFCCs=torch.stack([MFCCs,MFCCs,MFCCs])# 3채널로 복사.\n",
    "            MFCCs = MFCCs.squeeze(dim=1)\n",
    "        else:\n",
    "            #print(\"else\")\n",
    "            MFCCs = torch.from_numpy(MFCCs).type(torch.float32)\n",
    "            MFCCs=MFCCs.unsqueeze(0) #cnn 사용위해서 추가\n",
    "            #MFCCs = MFCCs.permute(2, 0, 1)\n",
    "        return MFCCs, self.classes.index(self.label[idx])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d05129d",
   "metadata": {},
   "source": [
    "# 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89052fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 하이퍼 파라미터\n",
    "BATCH_SIZE =  30 #한 배치당 30개 음성데이터 # 32 배수시에, 1개만 남는 경우가 발생해서.\n",
    "EPOCHS = 40 # 전체 데이터 셋을 40번 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bba97b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA LOADER 함수가 BATCH_size 단위로 분리해 지정.\n",
    "\n",
    "#확인을 위해 데이터셋 하나만 확인\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_train_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                               data_num=0,\n",
    "                                               training=True\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,\n",
    "                                           ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_test_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),\n",
    "                                               data_num=0,\n",
    "                                               training=False\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b15a86",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f866237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_train :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x2810cd9ba90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. 데이터 확인하기\n",
    "for (X_train,Y_train) in train_loader:\n",
    "    print(\"X_train : \",X_train.size(),'type:',X_train.type())\n",
    "    print(\"Y_train : \",Y_train.size(),'type:',Y_train.type())\n",
    "    break\n",
    "    \n",
    "print(Y_train[0])\n",
    "librosa.display.specshow(X_train[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / frame수: 400  /  feature수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a45b51bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_valid :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x28110d92700>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#valiation set 확인\n",
    "for (X_valid,Y_valid) in validation_loader:\n",
    "    print(\"X_valid : \",X_valid.size(),'type:',X_valid.type())\n",
    "    print(\"Y_valid : \",Y_valid.size(),'type:',Y_valid.type())\n",
    "    break\n",
    "\n",
    "print(Y_valid[0])\n",
    "librosa.display.specshow(X_valid[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / 3채널 / frame수: 400  /  feature수: 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec40ea4",
   "metadata": {},
   "source": [
    "# RESNET18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e1d59a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 \n",
    "# pretrained\n",
    "\n",
    "\n",
    "def model_initialize():\n",
    "    model = models.resnet18(pretrained=True).cuda()\n",
    "    model.ftrs = model.fc.in_features # in_features : fully connected의 입력수.\n",
    "    num_ftrs = model.fc.in_features\n",
    "\n",
    "    model.fc = nn.Sequential(nn.Linear(num_ftrs, 256),\n",
    "                             nn.BatchNorm1d(256),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(256,128),\n",
    "                             nn.BatchNorm1d(128),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(128,64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "\n",
    "    model = model.cuda()\n",
    "    return model\n",
    "model=model_initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c26ff30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "    (12): Linear(in_features=64, out_features=50, bias=True)\n",
      "    (13): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Dropout(p=0.5, inplace=False)\n",
      "    (16): Linear(in_features=50, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6097d312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 200, 7]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 200, 7]             128\n",
      "              ReLU-3           [-1, 64, 200, 7]               0\n",
      "         MaxPool2d-4           [-1, 64, 100, 4]               0\n",
      "            Conv2d-5           [-1, 64, 100, 4]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 100, 4]             128\n",
      "              ReLU-7           [-1, 64, 100, 4]               0\n",
      "            Conv2d-8           [-1, 64, 100, 4]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 100, 4]             128\n",
      "             ReLU-10           [-1, 64, 100, 4]               0\n",
      "       BasicBlock-11           [-1, 64, 100, 4]               0\n",
      "           Conv2d-12           [-1, 64, 100, 4]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 100, 4]             128\n",
      "             ReLU-14           [-1, 64, 100, 4]               0\n",
      "           Conv2d-15           [-1, 64, 100, 4]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 100, 4]             128\n",
      "             ReLU-17           [-1, 64, 100, 4]               0\n",
      "       BasicBlock-18           [-1, 64, 100, 4]               0\n",
      "           Conv2d-19           [-1, 128, 50, 2]          73,728\n",
      "      BatchNorm2d-20           [-1, 128, 50, 2]             256\n",
      "             ReLU-21           [-1, 128, 50, 2]               0\n",
      "           Conv2d-22           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-23           [-1, 128, 50, 2]             256\n",
      "           Conv2d-24           [-1, 128, 50, 2]           8,192\n",
      "      BatchNorm2d-25           [-1, 128, 50, 2]             256\n",
      "             ReLU-26           [-1, 128, 50, 2]               0\n",
      "       BasicBlock-27           [-1, 128, 50, 2]               0\n",
      "           Conv2d-28           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-29           [-1, 128, 50, 2]             256\n",
      "             ReLU-30           [-1, 128, 50, 2]               0\n",
      "           Conv2d-31           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-32           [-1, 128, 50, 2]             256\n",
      "             ReLU-33           [-1, 128, 50, 2]               0\n",
      "       BasicBlock-34           [-1, 128, 50, 2]               0\n",
      "           Conv2d-35           [-1, 256, 25, 1]         294,912\n",
      "      BatchNorm2d-36           [-1, 256, 25, 1]             512\n",
      "             ReLU-37           [-1, 256, 25, 1]               0\n",
      "           Conv2d-38           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-39           [-1, 256, 25, 1]             512\n",
      "           Conv2d-40           [-1, 256, 25, 1]          32,768\n",
      "      BatchNorm2d-41           [-1, 256, 25, 1]             512\n",
      "             ReLU-42           [-1, 256, 25, 1]               0\n",
      "       BasicBlock-43           [-1, 256, 25, 1]               0\n",
      "           Conv2d-44           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-45           [-1, 256, 25, 1]             512\n",
      "             ReLU-46           [-1, 256, 25, 1]               0\n",
      "           Conv2d-47           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-48           [-1, 256, 25, 1]             512\n",
      "             ReLU-49           [-1, 256, 25, 1]               0\n",
      "       BasicBlock-50           [-1, 256, 25, 1]               0\n",
      "           Conv2d-51           [-1, 512, 13, 1]       1,179,648\n",
      "      BatchNorm2d-52           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-53           [-1, 512, 13, 1]               0\n",
      "           Conv2d-54           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-55           [-1, 512, 13, 1]           1,024\n",
      "           Conv2d-56           [-1, 512, 13, 1]         131,072\n",
      "      BatchNorm2d-57           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-58           [-1, 512, 13, 1]               0\n",
      "       BasicBlock-59           [-1, 512, 13, 1]               0\n",
      "           Conv2d-60           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-61           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-62           [-1, 512, 13, 1]               0\n",
      "           Conv2d-63           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-64           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-65           [-1, 512, 13, 1]               0\n",
      "       BasicBlock-66           [-1, 512, 13, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                  [-1, 256]         131,328\n",
      "      BatchNorm1d-69                  [-1, 256]             512\n",
      "             ReLU-70                  [-1, 256]               0\n",
      "          Dropout-71                  [-1, 256]               0\n",
      "           Linear-72                  [-1, 128]          32,896\n",
      "      BatchNorm1d-73                  [-1, 128]             256\n",
      "             ReLU-74                  [-1, 128]               0\n",
      "          Dropout-75                  [-1, 128]               0\n",
      "           Linear-76                   [-1, 64]           8,256\n",
      "      BatchNorm1d-77                   [-1, 64]             128\n",
      "             ReLU-78                   [-1, 64]               0\n",
      "          Dropout-79                   [-1, 64]               0\n",
      "           Linear-80                   [-1, 50]           3,250\n",
      "      BatchNorm1d-81                   [-1, 50]             100\n",
      "             ReLU-82                   [-1, 50]               0\n",
      "          Dropout-83                   [-1, 50]               0\n",
      "           Linear-84                    [-1, 2]             102\n",
      "================================================================\n",
      "Total params: 11,353,340\n",
      "Trainable params: 11,353,340\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 8.16\n",
      "Params size (MB): 43.31\n",
      "Estimated Total Size (MB): 51.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# get the model summary\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 400, 13), device=DEVICE.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f2ca15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 학습\n",
    "def train(model,train_loader,optimizer, log_interval):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "    for batch_idx,(image,label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        #데이터들 장비에 할당\n",
    "        optimizer.zero_grad() # device 에 저장된 gradient 제거\n",
    "        output = model(image) # model로 output을 계산\n",
    "        loss = criterion(output, label) #loss 계산\n",
    "        train_loss += loss.item()\n",
    "        prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "        correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "        loss.backward() # loss 값을 이용해 gradient를 계산\n",
    "        optimizer.step() # Gradient 값을 이용해 파라미터 업데이트.\n",
    "    train_loss/=len(train_loader.dataset)\n",
    "    train_accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return train_loss,train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b09341bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. 학습 진행하며, validation 데이터로 모델 성능확인\n",
    "def evaluate(model,valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in valid_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            valid_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "            #true.false값을 sum해줌. item\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        valid_accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "        return valid_loss,valid_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae179080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로더 제작 함수\n",
    "\n",
    "def load_data(data_ind):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_train_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=True\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,\n",
    "                                               ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_test_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=False\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,) \n",
    "    return train_loader,validation_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d7e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 10. 학습 및 평가.\n",
    "# resnet18 pretrained true\n",
    "# kfold 적용\n",
    "\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = '../checkpoint/checkpoint_resnet18_true_'+str(data_ind)+'_i.pt'\n",
    "\n",
    "    early_stopping = EarlyStopping(patience = 5, verbose = True, path=check_path)\n",
    "    train_loader,validation_loader = load_data(data_ind-1)\n",
    "    \n",
    "    best_train_acc=0 # accuracy 기록용\n",
    "    best_valid_acc=0\n",
    "    \n",
    "    model=model_initialize()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "    \n",
    "    \n",
    "    print(\"[{} 교차검증] 학습 시작\\n ----- \".format(data_ind))\n",
    "    for Epoch in range(1,EPOCHS+1):\n",
    "        train_loss,train_accuracy=train(model,train_loader,optimizer,log_interval=31)\n",
    "        valid_loss,valid_accuracy = evaluate(model, validation_loader)\n",
    "\n",
    "\n",
    "        print(\"\\n[EPOCH:{}]\\t Train Loss:{:.4f}\\t Train Acc:{:.2f} %  | \\tValid Loss:{:.4f} \\tValid Acc: {:.2f} %\\n\".\n",
    "              format(Epoch,train_loss,train_accuracy,valid_loss,valid_accuracy))\n",
    "\n",
    "        early_stopping(valid_loss, model)\n",
    "        if -early_stopping.best_score == valid_loss:\n",
    "            best_train_acc, best_valid_acc = train_accuracy,valid_accuracy\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "                train_accs.append(best_train_acc)\n",
    "                valid_accs.append(best_valid_acc)\n",
    "                print(\"[{} 교차검증] Early stopping\".format(data_ind))\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6767ec8",
   "metadata": {},
   "source": [
    "# 모델 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6824ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] train ACC : 70.6495 |\t valid ACC: 70.1711 \n",
      "[2 교차검증] train ACC : 61.7881 |\t valid ACC: 59.5588 \n",
      "[3 교차검증] train ACC : 62.7679 |\t valid ACC: 64.2157 \n",
      "[4 교차검증] train ACC : 69.3815 |\t valid ACC: 75.2451 \n",
      "[5 교차검증] train ACC : 68.2180 |\t valid ACC: 67.4020 \n",
      "평균 검증 정확도 67.31854355434105 %\n"
     ]
    }
   ],
   "source": [
    "sum_valid=0\n",
    "for data_ind in range(5):\n",
    "    print(\"[{} 교차검증] train ACC : {:.4f} |\\t valid ACC: {:.4f} \".format(data_ind+1,train_accs[data_ind],valid_accs[data_ind] ))\n",
    "    sum_valid+=valid_accs[data_ind]\n",
    "    \n",
    "print(\"평균 검증 정확도\",sum_valid/5,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0967cf",
   "metadata": {},
   "source": [
    "# Model Test\n",
    "\n",
    "- test set\n",
    "- confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a19235bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix 계산\n",
    "#test set 계산.\n",
    "def test_evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    answers = []\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            answers +=label\n",
    "            predictions +=prediction\n",
    "            \n",
    "        return predictions,answers,test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca2e1ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[214.  57.]\n",
      " [ 65.  73.]]\n",
      "[[368. 174.]\n",
      " [113. 162.]]\n",
      "[[527. 286.]\n",
      " [147. 265.]]\n",
      "[[775. 309.]\n",
      " [225. 324.]]\n",
      "[[961. 393.]\n",
      " [274. 413.]]\n",
      "Accuracy : 67.3199% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.7781\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7097\n",
      "f score : 0.7424 \n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix (resnet18)\n",
    "# kfold의 confusion matrix는 계산 방법이 다르다.\n",
    "# 모델을 각각 불러와서 결과를 모두 합쳐줘야한다.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf = np.zeros((2,2))\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = '../checkpoint/checkpoint_resnet18_true_'+str(data_ind)+'_i.pt'\n",
    "    model.load_state_dict(torch.load(check_path))\n",
    "    _,validation_loader = load_data(data_ind-1)\n",
    "\n",
    "    predictions,answers,test_loss = test_evaluate(model, validation_loader)\n",
    "    predictions=[ dat.cpu().numpy() for dat in predictions]\n",
    "    answers=[ dat.cpu().numpy() for dat in answers]\n",
    "\n",
    "\n",
    "    cf += confusion_matrix(answers, predictions)\n",
    "    print(cf)\n",
    "\n",
    "acc = (cf[0,0]+cf[1,1])/(cf[0,0]+cf[0,1]+cf[1,0]+cf[1,1])\n",
    "precision=cf[0,0]/(cf[0,0]+cf[1,0])\n",
    "recall=cf[0,0]/(cf[0,0]+cf[0,1])\n",
    "fscore=2*precision*recall/(precision+recall)\n",
    "\n",
    "print(\"Accuracy : {:.4f}% \".format(acc*100))\n",
    "print(\"Precision (pathology 예측한 것중 맞는 것) : {:.4f}\".format(precision))\n",
    "print(\"recall (실제 pathology 중  예측이 맞는 것) : {:.4f}\".format(recall))\n",
    "print(\"f score : {:.4f} \".format(fscore))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "496.083px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
